{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f068e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "import os\n",
    "from typing import Any, Dict, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01985f",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560b8785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization and export utility functions for the project pipeline\n",
    "# All functions in this file are documented in English and follow snake_case naming convention\n",
    "\n",
    "'''\n",
    "Example usage:\n",
    "from src.utils.helpers import plot_metrics, plot_confusion_matrix, plot_histograms, plot_samples, export_metrics_csv, get_true_labels\n",
    "\n",
    "plot_metrics(results, 'fid', './results')\n",
    "plot_confusion_matrix(y_true, y_pred, labels=['Class 0', 'Class 1'], filename='./results/confusion_matrix.png')\n",
    "plot_histograms(originals, generated, 'scenario1', './results')\n",
    "plot_samples(originals, generated, 'scenario1', './results')\n",
    "export_metrics_csv(results, perf_results, './results/metrics.csv')\n",
    "labels = get_true_labels(test_loader)\n",
    "# Performance metrics keys: 'total_time', 'memory_MB', 'gpu_memory_MB', 'cost_per_image', 'flops', 'params'\n",
    "'''\n",
    "\n",
    "# --- Visualization functions ---\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "from logging.handlers import RotatingFileHandler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.metrics.image_metrics import ImageQualityMetric\n",
    "from src.metrics.segmentation_metrics import AssertivenessMetric\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, optimizer, device, num_epochs=1, model_type='cnn'):\n",
    "    \"\"\"\n",
    "    Train a model for a given number of epochs.\n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        dataloader: DataLoader for training data.\n",
    "        optimizer: Optimizer for model parameters.\n",
    "        device: Device to use ('cuda' or 'cpu').\n",
    "        num_epochs: Number of epochs to train.\n",
    "        model_type: Type of model ('cnn', 'gan', 'diffusion').\n",
    "    Returns:\n",
    "        Trained model.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        for batch in tqdm(dataloader, desc=f'Training {model_type} - Epoch {epoch+1}/{num_epochs}'):\n",
    "            if model_type == 'cnn':\n",
    "                x, y = batch\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                _, loss = model(x, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                losses.append(loss.item())\n",
    "            elif model_type == 'gan':\n",
    "                d_loss, g_loss = model.train_step(batch[0])\n",
    "                losses.append((d_loss, g_loss))\n",
    "            elif model_type == 'diffusion':\n",
    "                loss = model.train_step(batch[0], optimizer)\n",
    "                losses.append(loss)\n",
    "        if model_type == 'gan' and losses:\n",
    "            d_losses = [dl for dl, _ in losses]\n",
    "            g_losses = [gl for _, gl in losses]\n",
    "            print(f\"Average D loss in epoch {epoch+1}: {sum(d_losses)/len(d_losses):.4f}, G loss: {sum(g_losses)/len(g_losses):.4f}\")\n",
    "        else:\n",
    "            print(f\"Average loss in epoch {epoch+1}: {sum(losses)/len(losses) if losses else 0}\")\n",
    "    return model\n",
    "\n",
    "def validate_model(model, dataloader, device, model_type='cnn'):\n",
    "    \"\"\"\n",
    "    Validate a model on a given dataset.\n",
    "    Args:\n",
    "        model: The model to validate.\n",
    "        dataloader: DataLoader for validation data.\n",
    "        device: Device to use ('cuda' or 'cpu').\n",
    "        model_type: Type of model ('cnn', 'gan', 'diffusion').\n",
    "    Returns:\n",
    "        Average loss over the validation set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=f'Validation {model_type}'):\n",
    "            if model_type == 'cnn':\n",
    "                x, y = batch\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                _, loss = model(x, y)\n",
    "                losses.append(loss.item())\n",
    "            elif model_type == 'gan':\n",
    "                loss = model.validate_step(batch)\n",
    "                losses.append(loss)\n",
    "            elif model_type == 'diffusion':\n",
    "                loss = model.validate_step(batch)\n",
    "                losses.append(loss)\n",
    "    return sum(losses)/len(losses) if losses else 0\n",
    "\n",
    "def save_checkpoint(model, path):\n",
    "    \"\"\"\n",
    "    Save model weights to a file.\n",
    "    Args:\n",
    "        model: The model to save.\n",
    "        path: Path to the file.\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "def load_checkpoint(model, path, device):\n",
    "    \"\"\"\n",
    "    Load model weights from a file.\n",
    "    Args:\n",
    "        model: The model to load weights into.\n",
    "        path: Path to the file.\n",
    "        device: Device to map the model to.\n",
    "    Returns:\n",
    "        The model with loaded weights.\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(path, map_location=device))\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def setup_logging(log_dir=\"./logs\", log_file=\"pipeline.log\", level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Set up logging to file and console.\n",
    "    Args:\n",
    "        log_dir: Directory for log files.\n",
    "        log_file: Log file name.\n",
    "        level: Logging level.\n",
    "    Returns:\n",
    "        Configured logger.\n",
    "    \"\"\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_path = os.path.join(log_dir, log_file)\n",
    "    handler = RotatingFileHandler(log_path, maxBytes=5*1024*1024, backupCount=3)\n",
    "    formatter = logging.Formatter('[%(asctime)s] %(levelname)s %(name)s: %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(level)\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(handler)\n",
    "    # Also log to console\n",
    "    console = logging.StreamHandler()\n",
    "    console.setFormatter(formatter)\n",
    "    logger.addHandler(console)\n",
    "    return logger\n",
    "\n",
    "def plot_metrics(results, metric, results_dir):\n",
    "    \"\"\"\n",
    "    Plot a bar chart comparing a given metric across scenarios.\n",
    "    Args:\n",
    "        results (dict): Dictionary with scenario keys and metric values.\n",
    "        metric (str): Metric name to compare (e.g., 'fid', 'ssim', 'psnr').\n",
    "        results_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    labels = []\n",
    "    values = []\n",
    "    for key, res in results.items():\n",
    "        labels.append(key)\n",
    "        values.append(res[metric])\n",
    "    plt.bar(labels, values)\n",
    "    plt.title(f'Comparison of {metric.upper()}')\n",
    "    plt.ylabel(metric.upper())\n",
    "    plt.savefig(os.path.join(results_dir, f\"{metric}_comparison.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, filename):\n",
    "    \"\"\"\n",
    "    Plot and save a confusion matrix as a heatmap.\n",
    "    Args:\n",
    "        y_true (array-like): True class labels.\n",
    "        y_pred (array-like): Predicted class labels.\n",
    "        labels (list): List of class label names.\n",
    "        filename (str): Path to save the confusion matrix plot.\n",
    "    \"\"\"\n",
    "    cm = AssertivenessMetric('confusion').confusion(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_histograms(originals, generated, key, results_dir):\n",
    "    \"\"\"\n",
    "    Plot and save RGB and intensity histograms for a sample image.\n",
    "    Args:\n",
    "        originals (Tensor): Batch of original images.\n",
    "        generated (Tensor): Batch of generated images.\n",
    "        key (str): Scenario key for file naming.\n",
    "        results_dir (str): Directory to save the plots.\n",
    "    \"\"\"\n",
    "    metric = ImageQualityMetric('hist')\n",
    "    orig = originals[0].permute(1, 2, 0).cpu().numpy()\n",
    "    gen = generated[0].permute(1, 2, 0).cpu().numpy()\n",
    "    # RGB histogram\n",
    "    hist_orig = metric.calculate_histogram((orig * 255).astype(np.uint8), mode='rgb')\n",
    "    hist_gen = metric.calculate_histogram((gen * 255).astype(np.uint8), mode='rgb')\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(hist_orig, label='Original')\n",
    "    plt.plot(hist_gen, label='Generated')\n",
    "    plt.title('RGB Histogram (sample)')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{results_dir}/histogram_rgb_{key}.png\")\n",
    "    plt.close()\n",
    "    # Intensity histogram\n",
    "    hist_orig_int = metric.calculate_histogram((orig * 255).astype(np.uint8), mode='intensity')\n",
    "    hist_gen_int = metric.calculate_histogram((gen * 255).astype(np.uint8), mode='intensity')\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(hist_orig_int, label='Original')\n",
    "    plt.plot(hist_gen_int, label='Generated')\n",
    "    plt.title('Intensity Histogram (sample)')\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{results_dir}/histogram_intensity_{key}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_samples(originals, generated, key, results_dir):\n",
    "    \"\"\"\n",
    "    Plot and save a comparison of original and generated image samples.\n",
    "    Args:\n",
    "        originals (Tensor): Batch of original images.\n",
    "        generated (Tensor): Batch of generated images.\n",
    "        key (str): Scenario key for file naming.\n",
    "        results_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    n = min(5, originals.shape[0])\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(n):\n",
    "        plt.subplot(2, n, i+1)\n",
    "        plt.imshow(originals[i].permute(1, 2, 0).cpu().numpy().clip(0, 1))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.ylabel('Original')\n",
    "        plt.subplot(2, n, n+i+1)\n",
    "        plt.imshow(generated[i].permute(1, 2, 0).cpu().numpy().clip(0, 1))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.ylabel('Generated')\n",
    "    plt.suptitle('Samples: Original vs. Generated')\n",
    "    plt.savefig(f\"{results_dir}/samples_{key}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def export_metrics_csv(results, perf_results, filename):\n",
    "    \"\"\"\n",
    "    Export metrics and performance results to a CSV file.\n",
    "    Args:\n",
    "        results (dict): Dictionary with scenario keys and metric values.\n",
    "        perf_results (dict): Dictionary with scenario keys and performance metrics.\n",
    "        filename (str): Path to save the CSV file.\n",
    "    \"\"\"\n",
    "    fields = ['scenario', 'fid', 'ssim', 'psnr', 'total_time', 'memory_MB', 'gpu_memory_MB', 'cost_per_image', 'flops', 'params']\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
    "        writer.writeheader()\n",
    "        for scenario, metrics in results.items():\n",
    "            row = {'scenario': scenario}\n",
    "            row.update({k: metrics.get(k, None) for k in ['fid', 'ssim', 'psnr']})\n",
    "            perf = perf_results.get(scenario, {})\n",
    "            row['total_time'] = perf.get('total_time', None)\n",
    "            row['memory_MB'] = perf.get('memory_MB', None)\n",
    "            row['gpu_memory_MB'] = perf.get('gpu_memory_MB', None)\n",
    "            row['cost_per_image'] = perf.get('cost_per_image', None)\n",
    "            row['flops'] = perf.get('flops', None)\n",
    "            row['params'] = perf.get('params', None)\n",
    "            writer.writerow(row)\n",
    "\n",
    "def get_true_labels(test_loader):\n",
    "    \"\"\"\n",
    "    Extract true labels from a test data loader.\n",
    "    Args:\n",
    "        test_loader (DataLoader): DataLoader for the test set.\n",
    "    Returns:\n",
    "        np.ndarray: Array of true labels.\n",
    "    \"\"\"\n",
    "    y_true = []\n",
    "    for _, labels in test_loader:\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "    return np.array(y_true)\n",
    "\n",
    "# --- Data export and helper functions --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9cbd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configuration (could be moved to a config file or argparse)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DATA_DIR = \"./Amostras_celeba\"\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 64\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "RESULTS_DIR = \"./resultados\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "SCENARIOS = [\n",
    "    {\"model\": \"GAN\", \"mask\": False},\n",
    "    {\"model\": \"GAN\", \"mask\": True},\n",
    "    {\"model\": \"Diffusion\", \"mask\": False},\n",
    "    {\"model\": \"Diffusion\", \"mask\": True},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d47668c",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f40a2",
   "metadata": {},
   "source": [
    "## DiffusionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44cd0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Diffusion model for image generation.\n",
    "    Args:\n",
    "        denoise_network: Neural network for denoising.\n",
    "        T: Number of diffusion steps.\n",
    "        beta_start: Initial beta value.\n",
    "        beta_end: Final beta value.\n",
    "        device: Device to use ('cuda' or 'cpu').\n",
    "    \"\"\"\n",
    "    def __init__(self, denoise_network, T=1000, beta_start=1e-4, beta_end=0.02, device='cuda'):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.T = T\n",
    "        self.device = device\n",
    "        self.denoise_network = denoise_network.to(device)\n",
    "        self.register_buffer('betas', torch.linspace(beta_start, beta_end, T, device=device))\n",
    "        self.register_buffer('alphas', 1. - self.betas)\n",
    "        self.register_buffer('alpha_bars', torch.cumprod(self.alphas, dim=0))\n",
    "\n",
    "    def validate_step(self, batch):\n",
    "        \"\"\"\n",
    "        Perform a validation step for the diffusion model.\n",
    "        Args:\n",
    "            batch: Batch of real data.\n",
    "        Returns:\n",
    "            Validation loss.\n",
    "        \"\"\"\n",
    "        self.denoise_network.eval()\n",
    "        x0, _ = batch\n",
    "        x0 = x0.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            t = torch.randint(1, self.T + 1, (x0.shape[0],), device=self.device)\n",
    "            xt, noise = self.forward_diffusion(x0, t - 1)\n",
    "            predicted_noise = self.denoise_network(xt, t)\n",
    "            loss = nn.functional.mse_loss(predicted_noise, noise)\n",
    "        return loss.item()\n",
    "\n",
    "    def forward_diffusion(self, x0, t):\n",
    "        \"\"\"\n",
    "        Perform the forward diffusion process.\n",
    "        Args:\n",
    "            x0: Original images.\n",
    "            t: Diffusion step indices.\n",
    "        Returns:\n",
    "            Tuple of (noisy images, noise).\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(x0)\n",
    "        sqrt_alpha_bar = torch.sqrt(self.alpha_bars[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_bar = torch.sqrt(1. - self.alpha_bars[t])[:, None, None, None]\n",
    "        xt = sqrt_alpha_bar * x0 + sqrt_one_minus_alpha_bar * noise\n",
    "        return xt, noise\n",
    "\n",
    "    def train_step(self, x0, optimizer):\n",
    "        \"\"\"\n",
    "        Perform a training step for the diffusion model.\n",
    "        Args:\n",
    "            x0: Original images.\n",
    "            optimizer: Optimizer for the denoise network.\n",
    "        Returns:\n",
    "            Training loss.\n",
    "        \"\"\"\n",
    "        x0 = x0.to(self.device)\n",
    "        self.denoise_network.train()\n",
    "        optimizer.zero_grad()\n",
    "        t = torch.randint(1, self.T + 1, (x0.shape[0],), device=self.device)\n",
    "        xt, noise = self.forward_diffusion(x0, t - 1)\n",
    "        predicted_noise = self.denoise_network(xt, t)\n",
    "        loss = nn.functional.mse_loss(predicted_noise, noise)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def sample(self, num_samples, image_size):\n",
    "        \"\"\"\n",
    "        Generate samples from the diffusion model.\n",
    "        Args:\n",
    "            num_samples: Number of samples to generate.\n",
    "            image_size: Size of the generated images.\n",
    "        Returns:\n",
    "            Generated images.\n",
    "        \"\"\"\n",
    "        self.denoise_network.eval()\n",
    "        xt = torch.randn((num_samples, 3, image_size, image_size), device=self.device)\n",
    "        for t in tqdm(range(self.T, 0, -1), desc='Sampling'):\n",
    "            t_tensor = torch.full((num_samples,), t, device=self.device)\n",
    "            with torch.no_grad():\n",
    "                predicted_noise = self.denoise_network(xt, t_tensor)\n",
    "            alpha_t = self.alphas[t-1]\n",
    "            alpha_bar_t = self.alpha_bars[t-1]\n",
    "            sqrt_one_minus_alpha_bar_t = torch.sqrt(1. - alpha_bar_t)\n",
    "            mean = (xt - ((1. - alpha_t) / sqrt_one_minus_alpha_bar_t) * predicted_noise) / torch.sqrt(alpha_t)\n",
    "            if t > 1:\n",
    "                noise = torch.randn_like(xt)\n",
    "            else:\n",
    "                noise = torch.zeros_like(xt)\n",
    "            xt = mean + torch.sqrt(self.betas[t-1]) * noise\n",
    "        x0 = xt.clamp(-1., 1.)\n",
    "        return x0\n",
    "\n",
    "class DenoiseNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network for denoising in the diffusion model.\n",
    "    Args:\n",
    "        T: Number of diffusion steps (for time embedding).\n",
    "    \"\"\"\n",
    "    def __init__(self, T):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.time_embed = nn.Embedding(T, 256)\n",
    "        self.conv4 = nn.Conv2d(256 + 256, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        Forward pass for the denoise network.\n",
    "        Args:\n",
    "            x: Noisy images.\n",
    "            t: Diffusion step indices.\n",
    "        Returns:\n",
    "            Denoised images.\n",
    "        \"\"\"\n",
    "        h1 = torch.relu(self.conv1(x))\n",
    "        h2 = torch.relu(self.conv2(h1))\n",
    "        h3 = torch.relu(self.conv3(h2))\n",
    "        temb = self.time_embed(t - 1)\n",
    "        temb = temb.view(temb.shape[0], temb.shape[1], 1, 1)\n",
    "        temb = temb.expand(-1, -1, h3.shape[2], h3.shape[3])\n",
    "        h = torch.cat([h3, temb], dim=1)\n",
    "        h = torch.relu(self.conv4(h))\n",
    "        h = torch.relu(self.conv5(h))\n",
    "        h = self.conv6(h)\n",
    "        return h "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4863a69",
   "metadata": {},
   "source": [
    "## GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00f23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, img_channels=3, feature_map_size=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(noise_dim, feature_map_size*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_size*8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(feature_map_size*8, feature_map_size*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_size*4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(feature_map_size*4, feature_map_size*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_size*2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(feature_map_size*2, feature_map_size, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(feature_map_size, img_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=3, feature_map_size=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, feature_map_size, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(feature_map_size, feature_map_size*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_size*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(feature_map_size*2, feature_map_size*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_size*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(feature_map_size*4, feature_map_size*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(feature_map_size*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(feature_map_size*8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class GANTrainer:\n",
    "    \"\"\"\n",
    "    Trainer class for GAN models.\n",
    "    Args:\n",
    "        generator: Generator model.\n",
    "        discriminator: Discriminator model.\n",
    "        noise_dim: Dimension of the noise vector.\n",
    "        lr_D: Learning rate for discriminator.\n",
    "        lr_G: Learning rate for generator.\n",
    "        batch_size: Batch size.\n",
    "        device: Device to use ('cuda' or 'cpu').\n",
    "    \"\"\"\n",
    "    def __init__(self, generator, discriminator, noise_dim,\n",
    "                 lr_D=0.0002, lr_G=0.0002, batch_size=64, device='cuda'):\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.noise_dim = noise_dim\n",
    "        self.current_losses = {'g_loss': 0, 'd_loss': 0}\n",
    "        self.G = generator.to(device)\n",
    "        self.D = discriminator.to(device)\n",
    "        self.optimizer_D = optim.Adam(self.D.parameters(), lr=lr_D, betas=(0.5, 0.999))\n",
    "        self.optimizer_G = optim.Adam(self.G.parameters(), lr=lr_G, betas=(0.5, 0.999))\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    @property\n",
    "    def generator(self):\n",
    "        return self.G\n",
    "\n",
    "    def eval(self):\n",
    "        self.G.eval()\n",
    "        self.D.eval()\n",
    "\n",
    "    def train(self):\n",
    "        self.G.train()\n",
    "        self.D.train()\n",
    "\n",
    "    def validate_step(self, batch):\n",
    "        \"\"\"\n",
    "        Perform a validation step for the GAN.\n",
    "        Args:\n",
    "            batch: Batch of real data.\n",
    "        Returns:\n",
    "            Validation loss.\n",
    "        \"\"\"\n",
    "        real_data = batch[0].to(self.device)\n",
    "        batch_size = real_data.size(0)\n",
    "        with torch.no_grad():\n",
    "            real_labels = torch.ones(batch_size, 1, device=self.device)\n",
    "            fake_labels = torch.zeros(batch_size, 1, device=self.device)\n",
    "            real_output = self.D(real_data).view(batch_size, 1)\n",
    "            d_loss_real = self.criterion(real_output, real_labels)\n",
    "            noise = torch.randn(batch_size, self.noise_dim, 1, 1, device=self.device)\n",
    "            fake_data = self.G(noise)\n",
    "            fake_output = self.D(fake_data).view(batch_size, 1)\n",
    "            d_loss_fake = self.criterion(fake_output, fake_labels)\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            output = self.D(fake_data).view(batch_size, 1)\n",
    "            g_loss = self.criterion(output, real_labels)\n",
    "            total_loss = (d_loss + g_loss) / 2\n",
    "        return total_loss.item()\n",
    "\n",
    "    def train_step(self, real_data):\n",
    "        \"\"\"\n",
    "        Perform a training step for the GAN.\n",
    "        Args:\n",
    "            real_data: Batch of real data.\n",
    "        Returns:\n",
    "            Tuple of discriminator and generator losses.\n",
    "        \"\"\"\n",
    "        real_data = real_data.to(self.device)\n",
    "        batch_size = real_data.size(0)\n",
    "        self.optimizer_D.zero_grad()\n",
    "        real_labels = torch.ones(batch_size, 1, device=self.device)\n",
    "        real_output = self.D(real_data).view(batch_size, 1)\n",
    "        d_loss_real = self.criterion(real_output, real_labels)\n",
    "        noise = torch.randn(batch_size, self.noise_dim, 1, 1, device=self.device)\n",
    "        fake_data = self.G(noise)\n",
    "        fake_labels = torch.zeros(batch_size, 1, device=self.device)\n",
    "        fake_output = self.D(fake_data.detach()).view(batch_size, 1)\n",
    "        d_loss_fake = self.criterion(fake_output, fake_labels)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        self.optimizer_D.step()\n",
    "        self.optimizer_G.zero_grad()\n",
    "        noise = torch.randn(batch_size, self.noise_dim, 1, 1, device=self.device)\n",
    "        fake_data = self.G(noise)\n",
    "        output = self.D(fake_data).view(batch_size, 1)\n",
    "        g_loss = self.criterion(output, real_labels)\n",
    "        g_loss.backward()\n",
    "        self.optimizer_G.step()\n",
    "        return d_loss.item(), g_loss.item()\n",
    "\n",
    "    def train_full(self, dataloader, num_epochs):\n",
    "        \"\"\"\n",
    "        Train the GAN for a given number of epochs.\n",
    "        Args:\n",
    "            dataloader: DataLoader for training data.\n",
    "            num_epochs: Number of epochs to train.\n",
    "        \"\"\"\n",
    "        for epoch in range(num_epochs):\n",
    "            d_losses, g_losses = [], []\n",
    "            for real_data, _ in tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "                d_loss, g_loss = self.train_step(real_data)\n",
    "                d_losses.append(d_loss)\n",
    "                g_losses.append(g_loss)\n",
    "            self.current_losses['d_loss'] = np.mean(d_losses)\n",
    "            self.current_losses['g_loss'] = np.mean(g_losses)\n",
    "            print(f'Epoch {epoch+1}: D loss = {self.current_losses[\"d_loss\"]:.4f}, G loss = {self.current_losses[\"g_loss\"]:.4f}')\n",
    "\n",
    "    def get_current_losses(self):\n",
    "        \"\"\"\n",
    "        Get the current average losses for discriminator and generator.\n",
    "        Returns:\n",
    "            Dictionary with 'd_loss' and 'g_loss'.\n",
    "        \"\"\"\n",
    "        return self.current_losses "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20140932",
   "metadata": {},
   "source": [
    "## RecursiveCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a541cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class RecursiveCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Recursive Convolutional Neural Network for image classification.\n",
    "    Args:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        kernel_size (int): Size of the convolutional kernel.\n",
    "        num_iterations (int): Number of recursive iterations.\n",
    "        num_classes (int): Number of output classes.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, num_iterations, num_classes):\n",
    "        super(RecursiveCNN, self).__init__()\n",
    "        self.num_iterations = num_iterations\n",
    "        self.kernel_size = kernel_size\n",
    "        self.init_conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
    "        self.init_relu = nn.ReLU()\n",
    "        self.recursive_block = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "        self.conv_layer = nn.Conv2d(out_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(out_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        \"\"\"\n",
    "        Forward pass for the RecursiveCNN.\n",
    "        Args:\n",
    "            x: Input images.\n",
    "            y: Target labels (optional).\n",
    "        Returns:\n",
    "            Tuple of (predictions, loss).\n",
    "        \"\"\"\n",
    "        f = self.init_conv(x)\n",
    "        f = self.init_relu(f)\n",
    "        for t in range(self.num_iterations):\n",
    "            f_residual = self.recursive_block(f)\n",
    "            f_conv = self.conv_layer(f_residual)\n",
    "            f = self.relu(f_conv + f)\n",
    "            f = self.bn(f)\n",
    "        f_pool = self.global_pool(f)\n",
    "        f_pool = f_pool.view(f_pool.size(0), -1)\n",
    "        y_pred = F.softmax(self.fc(f_pool), dim=1)\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            loss = F.cross_entropy(self.fc(f_pool), y)\n",
    "        return y_pred, loss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da157a17",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1dba44",
   "metadata": {},
   "source": [
    "## ImageMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "816c262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from piq import LPIPS\n",
    "# from skimage import metrics\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class MetricBase(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for all metrics.\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.results = []\n",
    "\n",
    "    @abstractmethod\n",
    "    def calculate(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def add_result(self, value):\n",
    "        self.results.append(value)\n",
    "\n",
    "    def get_results(self):\n",
    "        return self.results\n",
    "\n",
    "class ImageQualityMetric(MetricBase):\n",
    "    \"\"\"\n",
    "    Class for image quality metrics.\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def calculate(self, *args, **kwargs):\n",
    "        # Default implementation (placeholder)\n",
    "        pass\n",
    "\n",
    "    def calculate_fid(self, real_images, fake_images, device='cuda'):\n",
    "        \"\"\"\n",
    "        Calculate Frechet Inception Distance (FID) between real and fake images.\n",
    "        Args:\n",
    "            real_images: Tensor of real images.\n",
    "            fake_images: Tensor of generated images.\n",
    "            device: Device to use ('cuda' or 'cpu').\n",
    "        Returns:\n",
    "            FID value (float).\n",
    "        \"\"\"\n",
    "        fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "        real_tensors = real_images.to(device)\n",
    "        fake_tensors = fake_images.to(device)\n",
    "        fid.update(real_tensors, real=True)\n",
    "        fid.update(fake_tensors, real=False)\n",
    "        value = fid.compute().item()\n",
    "        self.add_result(value)\n",
    "        return value\n",
    "\n",
    "    def calculate_ssim_psnr(self, real_img, fake_img):\n",
    "        \"\"\"\n",
    "        Calculate SSIM and PSNR between two images.\n",
    "        Args:\n",
    "            real_img: Numpy array of real image.\n",
    "            fake_img: Numpy array of generated image.\n",
    "        Returns:\n",
    "            Tuple (ssim, psnr).\n",
    "        \"\"\"\n",
    "        ssim_value = ssim(real_img, fake_img, channel_axis=2, win_size=3, data_range=1.0 if real_img.max() <= 1 else 255)\n",
    "        psnr_value = self.psnr(real_img, fake_img, data_range=1.0 if real_img.max() <= 1 else 255)\n",
    "        self.add_result({'ssim': ssim_value, 'psnr': psnr_value})\n",
    "        return ssim_value, psnr_value\n",
    "\n",
    "    def calculate_lpips(self, real_img, fake_img, device='cuda'):\n",
    "        \"\"\"\n",
    "        Calculate LPIPS metric between two images.\n",
    "        Args:\n",
    "            real_img: Numpy array or PIL image of real image.\n",
    "            fake_img: Numpy array or PIL image of generated image.\n",
    "            device: Device to use ('cuda' or 'cpu').\n",
    "        Returns:\n",
    "            LPIPS value (float).\n",
    "        \"\"\"\n",
    "        lpips = LPIPS(replace_pooling=True).to(device)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        real_tensor = transform(real_img).unsqueeze(0).to(device)\n",
    "        fake_tensor = transform(fake_img).unsqueeze(0).to(device)\n",
    "        value = lpips(real_tensor, fake_tensor).item()\n",
    "        self.add_result({'lpips': value})\n",
    "        return value\n",
    "\n",
    "    def psnr(self, real_img, fake_img, data_range=None):\n",
    "        \"\"\"\n",
    "        Calculate Peak Signal-to-Noise Ratio (PSNR) between two images.\n",
    "        Args:\n",
    "            real_img: Numpy array of real image.\n",
    "            fake_img: Numpy array of generated image.\n",
    "            data_range: Value range of the images.\n",
    "        Returns:\n",
    "            PSNR value (float).\n",
    "        \"\"\"\n",
    "        mse = np.mean((real_img.astype(np.float64) - fake_img.astype(np.float64)) ** 2)\n",
    "        if mse == 0:\n",
    "            return float('inf')\n",
    "        if data_range is None:\n",
    "            data_range = 1.0 if real_img.max() <= 1.0 else 255\n",
    "        return 20 * np.log10(data_range / np.sqrt(mse))\n",
    "\n",
    "    def calculate_histogram(self, img, mode='rgb', bins=256):\n",
    "        \"\"\"Calcula histograma RGB ou de intensidade.\"\"\"\n",
    "        if mode == 'rgb':\n",
    "            chans = cv2.split(img)\n",
    "            hist = [cv2.calcHist([c], [0], None, [bins], [0, 256]) for c in chans]\n",
    "            hist = np.concatenate(hist).ravel()\n",
    "        else:  # intensidade\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            hist = cv2.calcHist([gray], [0], None, [bins], [0, 256]).ravel()\n",
    "        hist = hist / (hist.sum() + 1e-8)  # normalização\n",
    "        return hist\n",
    "\n",
    "    def compare_histograms(self, hist1, hist2, method='chi-square'):\n",
    "        if method == 'chi-square':\n",
    "            score = cv2.compareHist(hist1.astype('float32'), hist2.astype('float32'), cv2.HISTCMP_CHISQR)\n",
    "        elif method == 'correlation':\n",
    "            score = cv2.compareHist(hist1.astype('float32'), hist2.astype('float32'), cv2.HISTCMP_CORREL)\n",
    "        elif method == 'intersection':\n",
    "            score = cv2.compareHist(hist1.astype('float32'), hist2.astype('float32'), cv2.HISTCMP_INTERSECT)\n",
    "        elif method == 'bhattacharyya':\n",
    "            score = cv2.compareHist(hist1.astype('float32'), hist2.astype('float32'), cv2.HISTCMP_BHATTACHARYYA)\n",
    "        else:\n",
    "            raise ValueError('Método de comparação de histograma não suportado')\n",
    "        self.add_result({f'hist_{method}': score})\n",
    "        return score\n",
    "\n",
    "    def batch_ssim(self, imgs1, imgs2):\n",
    "        \"\"\"Calcula SSIM para batches de imagens.\"\"\"\n",
    "        return [self.calculate_ssim_psnr(i1, i2)[0] for i1, i2 in zip(imgs1, imgs2)]\n",
    "\n",
    "    def batch_psnr(self, imgs1, imgs2):\n",
    "        \"\"\"Calcula PSNR para batches de imagens.\"\"\"\n",
    "        return [self.calculate_ssim_psnr(i1, i2)[1] for i1, i2 in zip(imgs1, imgs2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32245c31",
   "metadata": {},
   "source": [
    "## PerformanceMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0e9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import psutil\n",
    "import torch\n",
    "\n",
    "from src.metrics.image_metrics import MetricBase\n",
    "\n",
    "try:\n",
    "    from ptflops import get_model_complexity_info\n",
    "    PT_FLOPS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PT_FLOPS_AVAILABLE = False\n",
    "\n",
    "class PerformanceMetric(MetricBase):\n",
    "    \"\"\"\n",
    "    Class for performance metrics (time, memory, FLOPs, etc).\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def measure_time(self, func, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Measure execution time of a function.\n",
    "        Args:\n",
    "            func: Function to measure.\n",
    "            *args, **kwargs: Arguments for the function.\n",
    "        Returns:\n",
    "            Tuple (result, elapsed_time).\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time.time() - start\n",
    "        self.add_result({'execution_time': elapsed})\n",
    "        return result, elapsed\n",
    "\n",
    "    def measure_time_batch(self, func, dataloader, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Measure execution time for each batch in a dataloader.\n",
    "        Args:\n",
    "            func: Function to measure.\n",
    "            dataloader: DataLoader to iterate over.\n",
    "            *args, **kwargs: Arguments for the function.\n",
    "        Returns:\n",
    "            List of times per batch.\n",
    "        \"\"\"\n",
    "        times = []\n",
    "        for batch in dataloader:\n",
    "            start = time.time()\n",
    "            func(batch, *args, **kwargs)\n",
    "            times.append(time.time() - start)\n",
    "        self.add_result({'batch_time': times})\n",
    "        return times\n",
    "\n",
    "    def measure_time_image(self, func, images, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Measure execution time for each image in a list.\n",
    "        Args:\n",
    "            func: Function to measure.\n",
    "            images: List of images.\n",
    "            *args, **kwargs: Arguments for the function.\n",
    "        Returns:\n",
    "            List of times per image.\n",
    "        \"\"\"\n",
    "        times = []\n",
    "        for img in images:\n",
    "            start = time.time()\n",
    "            func(img, *args, **kwargs)\n",
    "            times.append(time.time() - start)\n",
    "        self.add_result({'image_time': times})\n",
    "        return times\n",
    "\n",
    "    def measure_memory(self):\n",
    "        \"\"\"\n",
    "        Measure current process memory usage (RAM).\n",
    "        Returns:\n",
    "            Memory usage in MB (float).\n",
    "        \"\"\"\n",
    "        process = psutil.Process()\n",
    "        mem = process.memory_info().rss / (1024 * 1024)  # in MB\n",
    "        self.add_result({'memory_MB': mem})\n",
    "        return mem\n",
    "\n",
    "    def measure_memory_gpu(self):\n",
    "        \"\"\"\n",
    "        Measure current GPU memory usage (if available).\n",
    "        Returns:\n",
    "            GPU memory usage in MB (float) or None.\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            mem = torch.cuda.max_memory_allocated() / (1024 * 1024)\n",
    "            self.add_result({'gpu_memory_MB': mem})\n",
    "            return mem\n",
    "        return None\n",
    "\n",
    "    def measure_flops(self, model, input_res):\n",
    "        \"\"\"\n",
    "        Measure FLOPs and parameter count for a model.\n",
    "        Args:\n",
    "            model: Model to analyze.\n",
    "            input_res: Input resolution tuple (C, H, W).\n",
    "        Returns:\n",
    "            Tuple (FLOPs, params) or (None, None) if not available.\n",
    "        \"\"\"\n",
    "        if PT_FLOPS_AVAILABLE:\n",
    "            macs, params = get_model_complexity_info(model, input_res, as_strings=False, print_per_layer_stat=False)\n",
    "            self.add_result({'FLOPs': macs * 2, 'params': params})\n",
    "            return macs * 2, params\n",
    "        else:\n",
    "            self.add_result({'FLOPs': None, 'params': None})\n",
    "            return None, None\n",
    "\n",
    "    def cost_per_image(self, total_time, n_images):\n",
    "        \"\"\"\n",
    "        Calculate computational cost per image.\n",
    "        Args:\n",
    "            total_time: Total execution time.\n",
    "            n_images: Number of images processed.\n",
    "        Returns:\n",
    "            Cost per image (float) or None.\n",
    "        \"\"\"\n",
    "        cost = total_time / n_images if n_images > 0 else None\n",
    "        self.add_result({'cost_per_image': cost})\n",
    "        return cost\n",
    "\n",
    "    def cost_per_batch(self, batch_times):\n",
    "        \"\"\"\n",
    "        Calculate computational cost per batch.\n",
    "        Args:\n",
    "            batch_times: List of times per batch.\n",
    "        Returns:\n",
    "            List of costs per batch.\n",
    "        \"\"\"\n",
    "        costs = [t for t in batch_times]\n",
    "        self.add_result({'cost_per_batch': costs})\n",
    "        return costs\n",
    "\n",
    "    def add_custom_cost(self, cost):\n",
    "        \"\"\"\n",
    "        Add a custom computational cost value.\n",
    "        Args:\n",
    "            cost: Custom cost value.\n",
    "        Returns:\n",
    "            The cost value.\n",
    "        \"\"\"\n",
    "        self.add_result({'custom_cost': cost})\n",
    "        return cost\n",
    "\n",
    "    def calculate(self, *args, **kwargs):\n",
    "        # Default implementation (placeholder)\n",
    "        pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a611173",
   "metadata": {},
   "source": [
    "## AssertivenessMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3176ed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchmetrics import F1Score, JaccardIndex, Precision, Recall\n",
    "\n",
    "from src.metrics.image_metrics import MetricBase\n",
    "\n",
    "\n",
    "class AssertivenessMetric(MetricBase):\n",
    "    \"\"\"\n",
    "    Class for assertiveness (segmentation) metrics.\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def calculate(self, *args, **kwargs):\n",
    "        # Default implementation (placeholder)\n",
    "        pass\n",
    "\n",
    "    def calculate_segmentation_metrics(self, mask_real, mask_pred, num_classes=2, device='cuda'):\n",
    "        \"\"\"\n",
    "        Calculate segmentation metrics (IoU, precision, recall, F1-score).\n",
    "        Args:\n",
    "            mask_real: Ground truth mask (numpy array).\n",
    "            mask_pred: Predicted mask (numpy array).\n",
    "            num_classes: Number of classes.\n",
    "            device: Device to use ('cuda' or 'cpu').\n",
    "        Returns:\n",
    "            Dictionary with metrics.\n",
    "        \"\"\"\n",
    "        mask_real = torch.from_numpy(mask_real).long()\n",
    "        mask_pred = torch.from_numpy(mask_pred).long()\n",
    "        task = 'binary' if num_classes == 2 else 'multiclass'\n",
    "        jaccard = JaccardIndex(task=task, num_classes=num_classes).to(device)\n",
    "        iou = jaccard(mask_pred, mask_real)\n",
    "        precision = Precision(task=task, num_classes=num_classes).to(device)\n",
    "        prec = precision(mask_pred, mask_real)\n",
    "        recall = Recall(task=task, num_classes=num_classes).to(device)\n",
    "        rec = recall(mask_pred, mask_real)\n",
    "        f1 = F1Score(task=task, num_classes=num_classes).to(device)\n",
    "        f1_score = f1(mask_pred, mask_real)\n",
    "        result = {\n",
    "            'iou': iou.item(),\n",
    "            'precision': prec.item(),\n",
    "            'recall': rec.item(),\n",
    "            'f1': f1_score.item()\n",
    "        }\n",
    "        self.add_result(result)\n",
    "        return result\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate accuracy between true and predicted labels.\n",
    "        Args:\n",
    "            y_true: Ground truth labels.\n",
    "            y_pred: Predicted labels.\n",
    "        Returns:\n",
    "            Accuracy (float).\n",
    "        \"\"\"\n",
    "        acc = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "        self.add_result({'accuracy': acc})\n",
    "        return acc\n",
    "\n",
    "    def confusion(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate confusion matrix.\n",
    "        Args:\n",
    "            y_true: Ground truth labels.\n",
    "            y_pred: Predicted labels.\n",
    "        Returns:\n",
    "            Confusion matrix (numpy array).\n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        self.add_result({'confusion_matrix': cm})\n",
    "        return cm\n",
    "\n",
    "    def mae(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate Mean Absolute Error (MAE).\n",
    "        Args:\n",
    "            y_true: Ground truth values.\n",
    "            y_pred: Predicted values.\n",
    "        Returns:\n",
    "            MAE (float).\n",
    "        \"\"\"\n",
    "        mae = np.mean(np.abs(np.array(y_true) - np.array(y_pred)))\n",
    "        self.add_result({'mae': mae})\n",
    "        return mae\n",
    "\n",
    "    def mse(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate Mean Squared Error (MSE).\n",
    "        Args:\n",
    "            y_true: Ground truth values.\n",
    "            y_pred: Predicted values.\n",
    "        Returns:\n",
    "            MSE (float).\n",
    "        \"\"\"\n",
    "        mse = np.mean((np.array(y_true) - np.array(y_pred)) ** 2)\n",
    "        self.add_result({'mse': mse})\n",
    "        return mse\n",
    "\n",
    "    def rmse(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate Root Mean Squared Error (RMSE).\n",
    "        Args:\n",
    "            y_true: Ground truth values.\n",
    "            y_pred: Predicted values.\n",
    "        Returns:\n",
    "            RMSE (float).\n",
    "        \"\"\"\n",
    "        rmse = np.sqrt(self.mse(y_true, y_pred))\n",
    "        self.add_result({'rmse': rmse})\n",
    "        return rmse\n",
    "\n",
    "    def mape(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate Mean Absolute Percentage Error (MAPE).\n",
    "        Args:\n",
    "            y_true: Ground truth values.\n",
    "            y_pred: Predicted values.\n",
    "        Returns:\n",
    "            MAPE (float).\n",
    "        \"\"\"\n",
    "        y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100\n",
    "        self.add_result({'mape': mape})\n",
    "        return mape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bade2f",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9516b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.data.dataset import CelebADataset\n",
    "\n",
    "\n",
    "def prepare_data(data_dir, batch_size, image_size, with_mask=False):\n",
    "    \"\"\"\n",
    "    Prepare data loaders for training, validation, and testing.\n",
    "    Args:\n",
    "        data_dir (str): Directory containing the dataset.\n",
    "        batch_size (int): Batch size for data loaders.\n",
    "        image_size (int): Size to resize images to (image_size, image_size).\n",
    "        with_mask (bool): Whether to use masks in the dataset.\n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader, test_loader)\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    dataset = CelebADataset(root_dir=data_dir, transform=transform, with_mask=with_mask)\n",
    "    total_size = len(dataset)\n",
    "    train_size = int(0.7 * total_size)\n",
    "    val_size = int(0.1 * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, [train_size, val_size, test_size], \n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    print(f\"Data split: Train={train_size}, Validation={val_size}, Test={test_size}\")\n",
    "    return train_loader, val_loader, test_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42a105f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloaders(with_mask: bool) -> Tuple[Any, Any, Any]:\n",
    "    \"\"\"Prepare train, validation, and test dataloaders.\"\"\"\n",
    "    return prepare_data(DATA_DIR, BATCH_SIZE, IMAGE_SIZE, with_mask=with_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6420288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "\n",
    "def apply_post_processing(images):\n",
    "    \"\"\"\n",
    "    Apply additional post-processing to a batch of images (Gaussian blur).\n",
    "    Args:\n",
    "        images (Tensor): Batch of images (N, C, H, W).\n",
    "    Returns:\n",
    "        Tensor: Batch of processed images.\n",
    "    \"\"\"\n",
    "    print(\"Applying additional post-processing to images...\")\n",
    "    batch_size, channels, height, width = images.shape\n",
    "    processed_images = images.clone()\n",
    "    kernel_size = 5\n",
    "    sigma = 1.0\n",
    "    for i in range(batch_size):\n",
    "        for c in range(channels):\n",
    "            processed_images[i, c] = torch.from_numpy(\n",
    "                np.array(\n",
    "                    Image.fromarray(\n",
    "                        np.uint8(((images[i, c].cpu().numpy() + 1) * 127.5))\n",
    "                    ).filter(\n",
    "                        ImageFilter.GaussianBlur(sigma)\n",
    "                    )\n",
    "                ) / 127.5 - 1\n",
    "            )\n",
    "    return processed_images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6edcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_models() -> Tuple[DiffusionModel, GANTrainer, RecursiveCNN]:\n",
    "    \"\"\"Initialize all required models.\"\"\"\n",
    "    denoise_net = DenoiseNetwork(T=1000)\n",
    "    diffusion_model = DiffusionModel(\n",
    "        denoise_network=denoise_net,\n",
    "        T=1000,\n",
    "        beta_start=1e-4,\n",
    "        beta_end=0.02,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    noise_dim = 100\n",
    "    generator = Generator(noise_dim=noise_dim)\n",
    "    discriminator = Discriminator()\n",
    "    gan_trainer = GANTrainer(\n",
    "        generator=generator,\n",
    "        discriminator=discriminator,\n",
    "        noise_dim=noise_dim,\n",
    "        lr_D=0.0002,\n",
    "        lr_G=0.0002,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    cnn_model = RecursiveCNN(\n",
    "        in_channels=3,\n",
    "        out_channels=64,\n",
    "        kernel_size=3,\n",
    "        num_iterations=5,\n",
    "        num_classes=NUM_CLASSES\n",
    "    ).to(DEVICE)\n",
    "    return diffusion_model, gan_trainer, cnn_model\n",
    "\n",
    "def generate_images(test_loader, model_type, diffusion_model, gan_trainer):\n",
    "    \"\"\"Generate images using the specified model.\"\"\"\n",
    "    originals = []\n",
    "    generated = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in test_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            batch_size = images.size(0)\n",
    "            originals.append(images.cpu())\n",
    "            generated_images = None\n",
    "            if model_type == \"Diffusion\":\n",
    "                t = torch.ones(batch_size, device=DEVICE).long() * 500\n",
    "                # Placeholder: replace with actual diffusion sampling\n",
    "                generated_images = images + 0.1 * torch.randn_like(images)\n",
    "            elif model_type == \"GAN\":\n",
    "                # noise = torch.randn(batch_size, gan_trainer.noise_dim, device=DEVICE)\n",
    "                noise = torch.randn(batch_size, gan_trainer.noise_dim, 1, 1, device=DEVICE)\n",
    "                generated_images = gan_trainer.generator(noise)\n",
    "            generated.append(generated_images.cpu())\n",
    "    originals = torch.cat(originals, dim=0)\n",
    "    generated = torch.cat(generated, dim=0)\n",
    "    return originals, generated\n",
    "\n",
    "def classify_images(images, cnn_model):\n",
    "    \"\"\"Classify images using the CNN model.\"\"\"\n",
    "    cnn_model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(images), BATCH_SIZE):\n",
    "            batch = images[i:i+BATCH_SIZE].to(DEVICE)\n",
    "            preds, _ = cnn_model(batch)\n",
    "            results.append(preds.cpu())\n",
    "    return torch.cat(results, dim=0)\n",
    "\n",
    "def to_uint8_tensor(imgs):\n",
    "    \"\"\"Convert images to uint8 tensor.\"\"\"\n",
    "    imgs = imgs.clone()\n",
    "    if imgs.min() < 0:\n",
    "        imgs = (imgs + 1) / 2\n",
    "    imgs = (imgs * 255).clamp(0, 255).to(torch.uint8)\n",
    "    return imgs\n",
    "\n",
    "def evaluate_images(originals, generated, device) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate generated images using FID, SSIM, and PSNR.\"\"\"\n",
    "    orig_uint8 = to_uint8_tensor(originals)\n",
    "    gen_uint8 = to_uint8_tensor(generated)\n",
    "    metric = ImageQualityMetric('comparison')\n",
    "    fid = metric.calculate_fid(orig_uint8, gen_uint8, device=device)\n",
    "    ssim_vals, psnr_vals = zip(*[\n",
    "        metric.calculate_ssim_psnr(\n",
    "            o.permute(1, 2, 0).cpu().numpy(),\n",
    "            g.permute(1, 2, 0).cpu().numpy()\n",
    "        )\n",
    "        for o, g in zip(orig_uint8, gen_uint8)\n",
    "    ])\n",
    "    ssim = sum(ssim_vals) / len(ssim_vals)\n",
    "    psnr = sum(psnr_vals) / len(psnr_vals)\n",
    "    return {\"fid\": fid, \"ssim\": ssim, \"psnr\": psnr}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44a6b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_images(originals, generated, device) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate generated images using FID, SSIM, and PSNR.\"\"\"\n",
    "    orig_uint8 = to_uint8_tensor(originals)\n",
    "    gen_uint8 = to_uint8_tensor(generated)\n",
    "    metric = ImageQualityMetric('comparison')\n",
    "    fid = metric.calculate_fid(orig_uint8, gen_uint8, device=device)\n",
    "    ssim_vals, psnr_vals = zip(*[\n",
    "        metric.calculate_ssim_psnr(\n",
    "            o.permute(1, 2, 0).cpu().numpy(),\n",
    "            g.permute(1, 2, 0).cpu().numpy()\n",
    "        )\n",
    "        for o, g in zip(orig_uint8, gen_uint8)\n",
    "    ])\n",
    "    ssim = sum(ssim_vals) / len(ssim_vals)\n",
    "    psnr = sum(psnr_vals) / len(psnr_vals)\n",
    "    return {\"fid\": fid, \"ssim\": ssim, \"psnr\": psnr}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8553bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main pipeline for comparing GAN and Diffusion models on image data.\n",
    "    \"\"\"\n",
    "    logger = setup_logging()\n",
    "    logger.info('Starting the model comparison pipeline.')\n",
    "    try:\n",
    "        diffusion_model, gan_trainer, cnn_model = initialize_models()\n",
    "        results = {}\n",
    "        perf_results = {}\n",
    "        num_epochs = 5\n",
    "        perf_metric = PerformanceMetric('performance')\n",
    "        for scenario in SCENARIOS:\n",
    "            logger.info(f\"Running scenario: {scenario['model']} {'with mask' if scenario['mask'] else 'without mask'}\")\n",
    "            train_loader, val_loader, test_loader = prepare_dataloaders(with_mask=scenario[\"mask\"])\n",
    "            # Training\n",
    "            if scenario[\"model\"] == \"Diffusion\":\n",
    "                optimizer_diff = torch.optim.Adam(diffusion_model.denoise_network.parameters(), lr=2e-4)\n",
    "                logger.info(\"Training Diffusion model...\")\n",
    "                _, train_time = perf_metric.measure_time(\n",
    "                    train_model, diffusion_model, train_loader, optimizer_diff, DEVICE, num_epochs, 'diffusion'\n",
    "                )\n",
    "                val_loss = validate_model(diffusion_model, val_loader, DEVICE, model_type='diffusion')\n",
    "                logger.info(f\"Diffusion validation: mean loss = {val_loss}\")\n",
    "                save_checkpoint(diffusion_model.denoise_network, f\"{RESULTS_DIR}/diffusion_{'mask' if scenario['mask'] else 'no_mask'}.pth\")\n",
    "                originals, generated = generate_images(test_loader, \"Diffusion\", diffusion_model, gan_trainer)\n",
    "            else:\n",
    "                logger.info(\"Training GAN model...\")\n",
    "                _, train_time = perf_metric.measure_time(\n",
    "                    train_model, gan_trainer, train_loader, None, DEVICE, num_epochs, 'gan'\n",
    "                )\n",
    "                val_loss = validate_model(gan_trainer, val_loader, DEVICE, model_type='gan')\n",
    "                logger.info(f\"GAN validation: mean loss = {val_loss}\")\n",
    "                save_checkpoint(gan_trainer.G, f\"{RESULTS_DIR}/ganG_{'mask' if scenario['mask'] else 'no_mask'}.pth\")\n",
    "                save_checkpoint(gan_trainer.D, f\"{RESULTS_DIR}/ganD_{'mask' if scenario['mask'] else 'no_mask'}.pth\")\n",
    "                originals, generated = generate_images(test_loader, \"GAN\", diffusion_model, gan_trainer)\n",
    "            # CNN training\n",
    "            optimizer_cnn = torch.optim.Adam(cnn_model.parameters(), lr=1e-3)\n",
    "            logger.info(\"Training CNN model...\")\n",
    "            _, train_time_cnn = perf_metric.measure_time(\n",
    "                train_model, cnn_model, train_loader, optimizer_cnn, DEVICE, num_epochs, 'cnn'\n",
    "            )\n",
    "            val_loss_cnn = validate_model(cnn_model, val_loader, DEVICE, model_type='cnn')\n",
    "            logger.info(f\"CNN validation: mean loss = {val_loss_cnn}\")\n",
    "            save_checkpoint(cnn_model, f\"{RESULTS_DIR}/cnn_{scenario['model']}_{'mask' if scenario['mask'] else 'no_mask'}.pth\")\n",
    "            processed_generated = apply_post_processing(generated)\n",
    "            class_cnn = classify_images(processed_generated, cnn_model)\n",
    "            metrics = evaluate_images(originals, processed_generated, DEVICE)\n",
    "            key = f\"{scenario['model']}_{'mask' if scenario['mask'] else 'no_mask'}\"\n",
    "            results[key] = metrics\n",
    "            logger.info(f\"Metrics for {key}: {metrics}\")\n",
    "            # Confusion matrix and visualizations\n",
    "            y_true = get_true_labels(test_loader)\n",
    "            y_pred = torch.argmax(class_cnn, dim=1).cpu().numpy()\n",
    "            plot_confusion_matrix(y_true, y_pred, labels=[\"Class 0\", \"Class 1\"], filename=f\"{RESULTS_DIR}/confusion_matrix_{key}.png\")\n",
    "            logger.info(f\"Confusion matrix saved at {RESULTS_DIR}/confusion_matrix_{key}.png\")\n",
    "            plot_histograms(originals, processed_generated, key, RESULTS_DIR)\n",
    "            plot_samples(originals, processed_generated, key, RESULTS_DIR)\n",
    "            logger.info(f\"Histograms and samples saved for {key}\")\n",
    "            # Performance metrics\n",
    "            mem = perf_metric.measure_memory()\n",
    "            mem_gpu = perf_metric.measure_memory_gpu()\n",
    "            total_time = train_time + train_time_cnn\n",
    "            cost_img = perf_metric.cost_per_image(total_time, len(test_loader.dataset))\n",
    "            logger.info(f\"Performance: total time={total_time:.2f}s, memory={mem:.2f}MB, GPU memory={mem_gpu}, cost per image={cost_img}\")\n",
    "            # FLOPs (example for CNN)\n",
    "            flops, params = None, None\n",
    "            if hasattr(cnn_model, 'fc'):\n",
    "                input_res = (3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "                flops, params = perf_metric.measure_flops(cnn_model, input_res)\n",
    "                logger.info(f\"CNN FLOPs: {flops}, parameters: {params}\")\n",
    "            # Save performance metrics\n",
    "            with open(f\"{RESULTS_DIR}/performance_{key}.txt\", \"w\") as f:\n",
    "                for r in perf_metric.get_results():\n",
    "                    f.write(str(r) + \"\\n\")\n",
    "            perf_results[key] = {\n",
    "                'total_time': total_time,\n",
    "                'memory_MB': mem,\n",
    "                'gpu_memory_MB': mem_gpu,\n",
    "                'cost_per_image': cost_img,\n",
    "                'flops': flops,\n",
    "                'params': params\n",
    "            }\n",
    "        # Plot and export results\n",
    "        for metric in [\"fid\", \"ssim\", \"psnr\"]:\n",
    "            plot_metrics(results, metric, RESULTS_DIR)\n",
    "        logger.info(\"Final Comparison Report:\")\n",
    "        for key, metrics in results.items():\n",
    "            logger.info(f\"{key}: {metrics}\")\n",
    "        best = min(results.items(), key=lambda x: x[1][\"fid\"])\n",
    "        logger.info(f\"Best model (lowest FID): {best[0]}\")\n",
    "        export_metrics_csv(results, perf_results, f\"{RESULTS_DIR}/comparative_metrics.csv\")\n",
    "        logger.info(f\"Numerical metrics exported to {RESULTS_DIR}/comparative_metrics.csv\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during pipeline execution: {e}\", exc_info=True)\n",
    "    logger.info('End of pipeline execution.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2856c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 21:54:57,967] INFO root: Starting the model comparison pipeline.\n",
      "[2025-04-29 21:54:58,156] INFO root: Running scenario: GAN without mask\n",
      "[2025-04-29 21:54:58,157] INFO root: Training GAN model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 images in ./Amostras_celeba\n",
      "Data split: Train=9, Validation=1, Test=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training gan - Epoch 1/5: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average D loss in epoch 1: 1.0911, G loss: 1.8647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training gan - Epoch 2/5: 100%|██████████| 1/1 [00:00<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average D loss in epoch 2: 0.6592, G loss: 3.1662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training gan - Epoch 3/5: 100%|██████████| 1/1 [00:00<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average D loss in epoch 3: 0.2529, G loss: 4.4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training gan - Epoch 4/5: 100%|██████████| 1/1 [00:00<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average D loss in epoch 4: 0.0815, G loss: 4.6975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training gan - Epoch 5/5: 100%|██████████| 1/1 [00:00<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average D loss in epoch 5: 0.1044, G loss: 4.8440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation gan: 100%|██████████| 1/1 [00:00<00:00, 16.06it/s]\n",
      "[2025-04-29 21:54:58,786] INFO root: GAN validation: mean loss = 1.1445976495742798\n",
      "[2025-04-29 21:54:58,869] INFO root: Training CNN model...\n",
      "Training cnn - Epoch 1/5: 100%|██████████| 1/1 [00:00<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 1: 0.7069723606109619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 2/5: 100%|██████████| 1/1 [00:00<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 2: 0.7201285362243652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 3/5: 100%|██████████| 1/1 [00:00<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 3: 0.6968564987182617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 4/5: 100%|██████████| 1/1 [00:00<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 4: 0.7020423412322998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 5/5: 100%|██████████| 1/1 [00:00<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 5: 0.6902891397476196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation cnn: 100%|██████████| 1/1 [00:00<00:00, 17.96it/s]\n",
      "[2025-04-29 21:54:59,426] INFO root: CNN validation: mean loss = 0.8147716522216797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying additional post-processing to images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 21:55:00,641] INFO root: Metrics for GAN_no_mask: {'fid': 364.22698974609375, 'ssim': np.float64(0.38879928778600564), 'psnr': np.float64(9.939539419576933)}\n",
      "[2025-04-29 21:55:00,767] INFO root: Confusion matrix saved at ./resultados/confusion_matrix_GAN_no_mask.png\n",
      "[2025-04-29 21:55:00,902] INFO root: Histograms and samples saved for GAN_no_mask\n",
      "[2025-04-29 21:55:00,904] INFO root: Performance: total time=1.06s, memory=1479.52MB, GPU memory=502.6728515625, cost per image=0.3541439374287923\n",
      "[2025-04-29 21:55:00,904] INFO root: CNN FLOPs: None, parameters: None\n",
      "[2025-04-29 21:55:00,904] INFO root: Running scenario: GAN with mask\n",
      "[2025-04-29 21:55:00,905] INFO root: Training GAN model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 images in ./Amostras_celeba\n",
      "Data split: Train=9, Validation=1, Test=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training gan - Epoch 1/5: 100%|██████████| 1/1 [00:00<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average D loss in epoch 1: 0.0873, G loss: 4.7473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training gan - Epoch 2/5: 100%|██████████| 1/1 [00:00<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average D loss in epoch 2: 0.0786, G loss: 4.6411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training gan - Epoch 3/5: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average D loss in epoch 3: 0.0661, G loss: 5.4260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training gan - Epoch 4/5: 100%|██████████| 1/1 [00:00<00:00, 12.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average D loss in epoch 4: 0.0862, G loss: 5.8009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training gan - Epoch 5/5: 100%|██████████| 1/1 [00:00<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average D loss in epoch 5: 0.0452, G loss: 6.1814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation gan: 100%|██████████| 1/1 [00:00<00:00, 15.56it/s]\n",
      "[2025-04-29 21:55:01,391] INFO root: GAN validation: mean loss = 1.7833818197250366\n",
      "[2025-04-29 21:55:01,480] INFO root: Training CNN model...\n",
      "Training cnn - Epoch 1/5: 100%|██████████| 1/1 [00:00<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 1: 0.6899327635765076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 2/5: 100%|██████████| 1/1 [00:00<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 2: 0.6965973377227783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 3/5: 100%|██████████| 1/1 [00:00<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 3: 0.6815457344055176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 4/5: 100%|██████████| 1/1 [00:00<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 4: 0.6756211519241333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 5/5: 100%|██████████| 1/1 [00:00<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 5: 0.6722304821014404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation cnn: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s]\n",
      "[2025-04-29 21:55:02,044] INFO root: CNN validation: mean loss = 0.7562283873558044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying additional post-processing to images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 21:55:03,302] INFO root: Metrics for GAN_mask: {'fid': 427.75677490234375, 'ssim': np.float64(0.3570487293974938), 'psnr': np.float64(9.843522739373057)}\n",
      "[2025-04-29 21:55:03,423] INFO root: Confusion matrix saved at ./resultados/confusion_matrix_GAN_mask.png\n",
      "[2025-04-29 21:55:03,551] INFO root: Histograms and samples saved for GAN_mask\n",
      "[2025-04-29 21:55:03,551] INFO root: Performance: total time=0.92s, memory=1660.88MB, GPU memory=723.3671875, cost per image=0.3072348435719808\n",
      "[2025-04-29 21:55:03,552] INFO root: CNN FLOPs: None, parameters: None\n",
      "[2025-04-29 21:55:03,552] INFO root: Running scenario: Diffusion without mask\n",
      "[2025-04-29 21:55:03,553] INFO root: Training Diffusion model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 images in ./Amostras_celeba\n",
      "Data split: Train=9, Validation=1, Test=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training diffusion - Epoch 1/5: 100%|██████████| 1/1 [00:00<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 1: 1.0055468082427979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training diffusion - Epoch 2/5: 100%|██████████| 1/1 [00:00<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 2: 1.0025639533996582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training diffusion - Epoch 3/5: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 3: 1.0038663148880005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training diffusion - Epoch 4/5: 100%|██████████| 1/1 [00:00<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 4: 0.9958980679512024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training diffusion - Epoch 5/5: 100%|██████████| 1/1 [00:00<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 5: 0.9912746548652649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation diffusion: 100%|██████████| 1/1 [00:00<00:00, 14.01it/s]\n",
      "[2025-04-29 21:55:04,214] INFO root: Diffusion validation: mean loss = 0.9800335764884949\n",
      "[2025-04-29 21:55:04,290] INFO root: Training CNN model...\n",
      "Training cnn - Epoch 1/5: 100%|██████████| 1/1 [00:00<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 1: 0.6679841876029968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 2/5: 100%|██████████| 1/1 [00:00<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 2: 0.6693249344825745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 3/5: 100%|██████████| 1/1 [00:00<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 3: 0.6601555943489075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 4/5: 100%|██████████| 1/1 [00:00<00:00,  9.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 4: 0.6558259129524231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 5/5: 100%|██████████| 1/1 [00:00<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 5: 0.6520708203315735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation cnn: 100%|██████████| 1/1 [00:00<00:00, 15.18it/s]\n",
      "[2025-04-29 21:55:04,885] INFO root: CNN validation: mean loss = 0.7394930720329285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying additional post-processing to images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 21:55:06,654] INFO root: Metrics for Diffusion_no_mask: {'fid': 339.1529235839844, 'ssim': np.float64(0.6317402597754299), 'psnr': np.float64(16.748415962127442)}\n",
      "[2025-04-29 21:55:06,783] INFO root: Confusion matrix saved at ./resultados/confusion_matrix_Diffusion_no_mask.png\n",
      "[2025-04-29 21:55:07,020] INFO root: Histograms and samples saved for Diffusion_no_mask\n",
      "[2025-04-29 21:55:07,021] INFO root: Performance: total time=1.12s, memory=1889.74MB, GPU memory=1170.55859375, cost per image=0.37186169624328613\n",
      "[2025-04-29 21:55:07,021] INFO root: CNN FLOPs: None, parameters: None\n",
      "[2025-04-29 21:55:07,021] INFO root: Running scenario: Diffusion with mask\n",
      "[2025-04-29 21:55:07,022] INFO root: Training Diffusion model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 images in ./Amostras_celeba\n",
      "Data split: Train=9, Validation=1, Test=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training diffusion - Epoch 1/5: 100%|██████████| 1/1 [00:00<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 1: 0.9937778115272522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training diffusion - Epoch 2/5: 100%|██████████| 1/1 [00:00<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 2: 0.9888983964920044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training diffusion - Epoch 3/5: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 3: 0.9810404181480408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training diffusion - Epoch 4/5: 100%|██████████| 1/1 [00:00<00:00,  8.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 4: 0.972320556640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training diffusion - Epoch 5/5: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 5: 0.9726639986038208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation diffusion: 100%|██████████| 1/1 [00:00<00:00, 13.72it/s]\n",
      "[2025-04-29 21:55:07,677] INFO root: Diffusion validation: mean loss = 0.9783014059066772\n",
      "[2025-04-29 21:55:07,765] INFO root: Training CNN model...\n",
      "Training cnn - Epoch 1/5: 100%|██████████| 1/1 [00:00<00:00,  9.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 1: 0.6476728916168213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 2/5: 100%|██████████| 1/1 [00:00<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 2: 0.6461507081985474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 3/5: 100%|██████████| 1/1 [00:00<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 3: 0.6387321949005127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 4/5: 100%|██████████| 1/1 [00:00<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 4: 0.6433608531951904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training cnn - Epoch 5/5: 100%|██████████| 1/1 [00:00<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss in epoch 5: 0.6315460801124573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation cnn: 100%|██████████| 1/1 [00:00<00:00, 13.32it/s]\n",
      "[2025-04-29 21:55:08,400] INFO root: CNN validation: mean loss = 0.689679741859436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying additional post-processing to images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 21:55:10,190] INFO root: Metrics for Diffusion_mask: {'fid': 357.6922912597656, 'ssim': np.float64(0.6267254322373179), 'psnr': np.float64(16.58528720173405)}\n",
      "/home/victor/projects/ai_andrea/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n",
      "[2025-04-29 21:55:10,328] INFO root: Confusion matrix saved at ./resultados/confusion_matrix_Diffusion_mask.png\n",
      "[2025-04-29 21:55:10,473] INFO root: Histograms and samples saved for Diffusion_mask\n",
      "[2025-04-29 21:55:10,473] INFO root: Performance: total time=1.14s, memory=1906.97MB, GPU memory=1170.55859375, cost per image=0.37881962458292645\n",
      "[2025-04-29 21:55:10,474] INFO root: CNN FLOPs: None, parameters: None\n",
      "[2025-04-29 21:55:10,569] INFO root: Final Comparison Report:\n",
      "[2025-04-29 21:55:10,570] INFO root: GAN_no_mask: {'fid': 364.22698974609375, 'ssim': np.float64(0.38879928778600564), 'psnr': np.float64(9.939539419576933)}\n",
      "[2025-04-29 21:55:10,570] INFO root: GAN_mask: {'fid': 427.75677490234375, 'ssim': np.float64(0.3570487293974938), 'psnr': np.float64(9.843522739373057)}\n",
      "[2025-04-29 21:55:10,570] INFO root: Diffusion_no_mask: {'fid': 339.1529235839844, 'ssim': np.float64(0.6317402597754299), 'psnr': np.float64(16.748415962127442)}\n",
      "[2025-04-29 21:55:10,571] INFO root: Diffusion_mask: {'fid': 357.6922912597656, 'ssim': np.float64(0.6267254322373179), 'psnr': np.float64(16.58528720173405)}\n",
      "[2025-04-29 21:55:10,571] INFO root: Best model (lowest FID): Diffusion_no_mask\n",
      "[2025-04-29 21:55:10,572] INFO root: Numerical metrics exported to ./resultados/comparative_metrics.csv\n",
      "[2025-04-29 21:55:10,572] INFO root: End of pipeline execution.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
